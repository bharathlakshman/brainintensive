{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "# MapNode\n",
    "\n",
    "If you want to iterate over a list of inputs, but need to feed all iterated outputs afterwards as one input (an array) to the next node, you need to use a **``MapNode``**. A ``MapNode`` is quite similar to a normal ``Node``, but it can take a list of inputs and operate over each input separately, ultimately returning a list of outputs. (The main homepage has a [nice section](http://nipype.readthedocs.io/en/latest/users/mapnode_and_iterables.html) about ``MapNode`` and ``iterables`` if you want to learn more).\n",
    "\n",
    "Let's demonstrate this with a simple function interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import Function\n",
    "def square_func(x):\n",
    "    return x ** 2\n",
    "square = Function([\"x\"], [\"f_x\"], square_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We see that this function just takes a numeric input and returns its squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square.run(x=2).outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What if we wanted to square a list of numbers? We could set an iterable and just split up the workflow in multiple sub-workflows. But say we were making a simple workflow that squared a list of numbers and then summed them. The sum node would expect a list, but using an iterable would make a bunch of sum nodes, and each would get one number from the list. The solution here is to use a `MapNode`.\n",
    "\n",
    "The `MapNode` constructor has a field called `iterfield`, which tells it what inputs should be expecting a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import MapNode\n",
    "square_node = MapNode(square, name=\"square\", iterfield=[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170301-21:57:47,860 workflow INFO:\n",
      "\t Executing node square in dir: /tmp/tmpZKVt49/square\n",
      "170301-21:57:47,870 workflow INFO:\n",
      "\t Executing node _square0 in dir: /tmp/tmpZKVt49/square/mapflow/_square0\n",
      "170301-21:57:47,882 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:47,887 workflow INFO:\n",
      "\t Executing node _square1 in dir: /tmp/tmpZKVt49/square/mapflow/_square1\n",
      "170301-21:57:47,906 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:47,911 workflow INFO:\n",
      "\t Executing node _square2 in dir: /tmp/tmpZKVt49/square/mapflow/_square2\n",
      "170301-21:57:47,923 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:47,926 workflow INFO:\n",
      "\t Executing node _square3 in dir: /tmp/tmpZKVt49/square/mapflow/_square3\n",
      "170301-21:57:47,936 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_node.inputs.x = range(4)\n",
    "square_node.run().outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because `iterfield` can take a list of names, you can operate over multiple sets of data, as long as they're the same length. The values in each list will be paired; it does not compute a combinatoric product of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def power_func(x, y):\n",
    "    return x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170301-21:57:47,970 workflow INFO:\n",
      "\t Executing node power in dir: /tmp/tmpJPLPn8/power\n",
      "170301-21:57:47,985 workflow INFO:\n",
      "\t Executing node _power0 in dir: /tmp/tmpJPLPn8/power/mapflow/_power0\n",
      "170301-21:57:47,999 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:48,2 workflow INFO:\n",
      "\t Executing node _power1 in dir: /tmp/tmpJPLPn8/power/mapflow/_power1\n",
      "170301-21:57:48,15 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:48,20 workflow INFO:\n",
      "\t Executing node _power2 in dir: /tmp/tmpJPLPn8/power/mapflow/_power2\n",
      "170301-21:57:48,34 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:48,43 workflow INFO:\n",
      "\t Executing node _power3 in dir: /tmp/tmpJPLPn8/power/mapflow/_power3\n",
      "170301-21:57:48,59 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "[1, 1, 4, 27]\n"
     ]
    }
   ],
   "source": [
    "power = Function([\"x\", \"y\"], [\"f_xy\"], power_func)\n",
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\", \"y\"])\n",
    "power_node.inputs.x = range(4)\n",
    "power_node.inputs.y = range(4)\n",
    "print(power_node.run().outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "But not every input needs to be an iterfield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170301-21:57:48,84 workflow INFO:\n",
      "\t Executing node power in dir: /tmp/tmphJmuk0/power\n",
      "170301-21:57:48,96 workflow INFO:\n",
      "\t Executing node _power0 in dir: /tmp/tmphJmuk0/power/mapflow/_power0\n",
      "170301-21:57:48,112 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:48,117 workflow INFO:\n",
      "\t Executing node _power1 in dir: /tmp/tmphJmuk0/power/mapflow/_power1\n",
      "170301-21:57:48,131 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:48,135 workflow INFO:\n",
      "\t Executing node _power2 in dir: /tmp/tmphJmuk0/power/mapflow/_power2\n",
      "170301-21:57:48,150 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "170301-21:57:48,159 workflow INFO:\n",
      "\t Executing node _power3 in dir: /tmp/tmphJmuk0/power/mapflow/_power3\n",
      "170301-21:57:48,176 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "[0, 1, 8, 27]\n"
     ]
    }
   ],
   "source": [
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\"])\n",
    "power_node.inputs.x = range(4)\n",
    "power_node.inputs.y = 3\n",
    "print(power_node.run().outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "As in the case of `iterables`, each underlying `MapNode` execution can happen in **parallel**. Hopefully, you see how these tools allow you to write flexible, reusable workflows that will help you processes large amounts of data efficiently and reproducibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Why is this important?\n",
    "\n",
    "Let's consider we have multiple functional images (A) and each of them should be motioned corrected (B1, B2, B3,..). But afterwards, we want to put them all together into a GLM, i.e. the input for the GLM should be an array of [B1, B2, B3, ...]. [Iterables](basic_iteration.ipynb) can't do that. They would split up the pipeline. Therefore, we need **MapNodes**.\n",
    "\n",
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "Let's look at a simple example, where we want to motion correct two functional images. For this we need two nodes:\n",
    " - Gunzip, to unzip the files (plural)\n",
    " - Realign, to do the motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.spm import Realign\n",
    "from nipype.pipeline.engine import Node, MapNode, Workflow\n",
    "\n",
    "files = ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz',\n",
    "         '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz']\n",
    "\n",
    "realign = Node(Realign(register_to_mean=True),\n",
    "               name='motion_correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we try to specify the input for the **Gunzip** node with a simple **Node**, we get the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TraitError",
     "evalue": "The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz', '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz'] <type 'list'> was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraitError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4c705ede4d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgunzip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGunzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gunzip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgunzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype/interfaces/traits_extension.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0;34m'fast validator'\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mvalidated_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidated_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/traits/trait_types.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_editor\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/traits/trait_handlers.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m    171\u001b[0m         raise TraitError( object, name, self.full_info( object, name, value ),\n\u001b[0;32m--> 172\u001b[0;31m                           value )\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull_info\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTraitError\u001b[0m: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz', '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz'] <type 'list'> was specified."
     ]
    }
   ],
   "source": [
    "gunzip = Node(Gunzip(), name='gunzip',)\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```bash\n",
    "TraitError: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz', '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz'] <type 'list'> was specified.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "But if we do it with a **MapNode**, it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gunzip = MapNode(Gunzip(), name='gunzip',\n",
    "                 iterfield=['in_file'])\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we just have to create a workflow, connect the nodes and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mcflow = Workflow(name='realign_with_spm')\n",
    "mcflow.connect(gunzip, 'out_file', realign, 'in_files')\n",
    "mcflow.base_dir = '/data'\n",
    "mcflow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
