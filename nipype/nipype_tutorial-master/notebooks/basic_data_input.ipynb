{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Input\n",
    "\n",
    "To do any computation, you need to have data. Getting the data in the framework of a workflow is therefore the first step of every analysis. Nipype provides many different modules to grab or select the data:\n",
    "\n",
    "    DataFinder\n",
    "    DataGrabber\n",
    "    FreeSurferSource\n",
    "    JSONFileGrabber\n",
    "    S3DataGrabber\n",
    "    SSHDataGrabber\n",
    "    SelectFiles\n",
    "    XNATSource\n",
    "\n",
    "This tutorial will only cover some of them. For the rest, see the section [``interfaces.io``](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html) on the official homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset structure\n",
    "\n",
    "To be able to import data, you first need to be aware about the structure of your dataset. The structure of the dataset for this tutorial is according to BIDS, and looks as follows:\n",
    "\n",
    "    ds102\n",
    "    ├── CHANGES\n",
    "    ├── dataset_description.json\n",
    "    ├── participants.tsv\n",
    "    ├── README\n",
    "    ├── sub-01\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-01_T1w.nii.gz\n",
    "    │   └── func\n",
    "    │       ├── sub-01_task-flanker_run-1_bold.nii.gz\n",
    "    │       ├── sub-01_task-flanker_run-1_events.tsv\n",
    "    │       ├── sub-01_task-flanker_run-2_bold.nii.gz\n",
    "    │       └── sub-01_task-flanker_run-2_events.tsv\n",
    "    ├── sub-02\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-02_T1w.nii.gz\n",
    "    │   └── func\n",
    "    │       ├── sub-02_task-flanker_run-1_bold.nii.gz\n",
    "    │       ├── sub-02_task-flanker_run-1_events.tsv\n",
    "    │       ├── sub-02_task-flanker_run-2_bold.nii.gz\n",
    "    │       └── sub-02_task-flanker_run-2_events.tsv\n",
    "    ├── sub-03\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-03_T1w.nii.gz\n",
    "    │   └── func\n",
    "    │       ├── sub-03_task-flanker_run-1_bold.nii.gz\n",
    "    │       ├── sub-03_task-flanker_run-1_events.tsv\n",
    "    │       ├── sub-03_task-flanker_run-2_bold.nii.gz\n",
    "    │       └── sub-03_task-flanker_run-2_events.tsv\n",
    "    ├── ...\n",
    "    .\n",
    "    └── task-flanker_bold.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DataGrabber\n",
    "\n",
    "``DataGrabber`` is a generic data grabber module that wraps around ``glob`` to select your neuroimaging data in an intelligent way. As an example, let's assume we want to grab the anatomical and functional images of a certain subject.\n",
    "\n",
    "First, we need to create the ``DataGrabber`` node. This node needs to have some input fields for all dynamic parameters (e.g. subject identifier, task identifier), as well as the two desired output fields ``anat`` and ``func``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import DataGrabber, Node\n",
    "\n",
    "# Create DataGrabber node\n",
    "dg = Node(DataGrabber(infields=['subject_id', 'task_id'],\n",
    "                      outfields=['anat', 'func']),\n",
    "          name='datagrabber')\n",
    "\n",
    "# Location of the dataset folder\n",
    "dg.inputs.base_directory = '/data/ds102'\n",
    "\n",
    "# Necessary default parameters\n",
    "dg.inputs.template = '*'\n",
    "dg.inputs.sort_filelist = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Second, we know that the two files we desire are the the following location:\n",
    "\n",
    "    anat = /data/ds102/sub-01/anat/sub-01_T1w.nii.gz\n",
    "    func = /data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz\n",
    "\n",
    "We see that the two files only have two dynamic parameters between subjects and conditions:\n",
    "\n",
    "    subject_id: in this case 'sub-01'\n",
    "    task_id: in this case 1\n",
    "\n",
    "This means that we can rewrite the paths as follows:\n",
    "\n",
    "    anat = /data/ds102/[subject_id]/anat/[subject_id]_T1w.nii.gz\n",
    "    func = /data/ds102/[subject_id]/func/[subject_id]_task-flanker_run-[task_id]_bold.nii.gz\n",
    "\n",
    "Therefore, we need the parameter ``subject_id`` for the anatomical image and the parameter ``subject_id`` and ``task_id`` for the functional image. In the context of DataGabber, this is specified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dg.inputs.template_args = {'anat': [['subject_id']],\n",
    "                           'func': [['subject_id', 'task_id']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, comes the most important part of DataGrabber. We need to specify the template structure to find the specific data. This can be done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dg.inputs.field_template = {'anat': '%s/anat/*_T1w.nii.gz',\n",
    "                            'func': '%s/func/*run-%d_bold.nii.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You'll notice that we use ``%s``, ``%02d`` and ``*`` for placeholders in the data paths. ``%s`` is a placeholder for a string and is filled out by ``subject_id``. ``%02d`` is a placeholder for a integer number and is filled out by ``task_id``. ``*`` is used as a wild card, e.g. a placeholder for any possible string combination. This is all to set up the ``DataGrabber`` node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now it is up to you how you want to feed the dynamic parameters into the node. You can either do this by using another node (e.g. ``IdentityInterface``) and feed ``subject_id`` and ``task_id`` as connections to the ``DataGrabber`` node or specify them directly as node inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using the IdentityInterface\n",
    "from nipype import IdentityInterface\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'contrasts']),\n",
    "                  name=\"infosource\")\n",
    "infosource.inputs.contrasts = 1\n",
    "subject_list = ['sub-01',\n",
    "                'sub-02',\n",
    "                'sub-03',\n",
    "                'sub-04',\n",
    "                'sub-05']\n",
    "infosource.iterables = [('subject_id', subject_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you only have to connect ``infosource`` with your ``DataGrabber`` and run the workflow to iterate over subjects 1, 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you specify the inputs to the ``DataGrabber`` node directly, you can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Specifying the input fields of DataGrabber directly\n",
    "dg.inputs.subject_id = 'sub-01'\n",
    "dg.inputs.task_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's run the ``DataGrabber`` node and let's look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170301-21:53:31,59 workflow INFO:\n",
      "\t Executing node datagrabber in dir: /tmp/tmp6AloiV/datagrabber\n",
      "170301-21:53:31,84 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "\n",
      "anat = /data/ds102/sub-01/anat/sub-01_T1w.nii.gz\n",
      "func = /data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print dg.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SelectFiles\n",
    "\n",
    "`SelectFiles` is a more flexible alternative to `DataGrabber`. It uses the {}-based string formating syntax to plug values into string templates and collect the data. These templates can also be combined with glob wild cards. The field names in the formatting template (i.e. the terms in braces) will become inputs fields on the interface, and the keys in the templates dictionary will form the output fields.\n",
    "\n",
    "Let's focus again on the data we want to import:\n",
    "\n",
    "    anat = /data/ds102/sub-01/anat/sub-01_T1w.nii.gz\n",
    "    func = /data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz\n",
    "    \n",
    "Now, we can replace those paths with the accoridng {}-based strings.\n",
    "\n",
    "    anat = /data/ds102/{subject_id}/anat/{subject_id}_T1w.nii.gz\n",
    "    func = /data/ds102/{subject_id}/func/{subject_id}_task-flanker_run-{task_id}_bold.nii.gz\n",
    "\n",
    "How would this look like as a `SelectFiles` node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': '{subject_id}/anat/{subject_id}_T1w.nii.gz',\n",
    "             'func': '{subject_id}/func/{subject_id}_task-flanker_run-{task_id}_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds102'\n",
    "\n",
    "# Feed {}-based placeholder strings with values\n",
    "sf.inputs.subject_id = 'sub-01'\n",
    "sf.inputs.task_id = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check if we get what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170301-21:53:57,750 workflow INFO:\n",
      "\t Executing node selectfiles in dir: /tmp/tmpejvdlC/selectfiles\n",
      "170301-21:53:57,763 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "\n",
      "anat = /data/ds102/sub-01/anat/sub-01_T1w.nii.gz\n",
      "func = /data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perfect! But why is `SelectFiles` more flexible than `DataGrabber`? First, you perhaps noticed that with the {}-based string, we can reuse the same input (e.g. `subject_id`) multiple time in the same string, without feeding it multiple times into the template.\n",
    "\n",
    "Additionally, you can also select multiple files without the need of an iterable node. For example, let's assume we want to select both functional images (`'run-1'` and `'run-2'`) at once. We can do this by using the following file template:\n",
    "\n",
    "    {subject_id}_task-flanker_run-[1,2]_bold.nii.gz'\n",
    "\n",
    "Let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170301-21:54:03,222 workflow INFO:\n",
      "\t Executing node selectfiles in dir: /tmp/tmpjgAYwb/selectfiles\n",
      "170301-21:54:03,259 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "\n",
      "anat = /data/ds102/sub-01/anat/sub-01_T1w.nii.gz\n",
      "func = ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz', '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "from os.path import abspath as opap\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': '{subject_id}/anat/{subject_id}_T1w.nii.gz',\n",
    "             'func': '{subject_id}/func/{subject_id}_task-flanker_run-[1,2]_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds102'\n",
    "\n",
    "# Feed {}-based placeholder strings with values\n",
    "sf.inputs.subject_id = 'sub-01'\n",
    "\n",
    "# Print SelectFiles output\n",
    "print sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see, now `func` contains two file paths, one for the first and one for the second run. As a side node, you could have also gotten them same thing with the wild card `*`:\n",
    "\n",
    "    {subject_id}_task-flanker_run-*_bold.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## FreeSurferSource\n",
    "\n",
    "***Note: FreeSurfer and the recon-all output is not included in this tutorial.***\n",
    "\n",
    "`FreeSurferSource` is a specific case of a file grabber that felicitates the data import of outputs from the FreeSurfer recon-all algorithm. This of course requires that you've already run `recon-all` on your subject.\n",
    "\n",
    "Before you can run `FreeSurferSource`, you first have to specify the path to the FreeSurfer output folder, i.e. you have to specify the SUBJECTS_DIR variable. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.freesurfer import FSCommand\n",
    "from os.path import abspath as opap\n",
    "\n",
    "# Path to your freesurfer output folder\n",
    "fs_dir = opap('/data/ds102/freesurfer')\n",
    "\n",
    "# Set SUBJECTS_DIR\n",
    "FSCommand.set_default_subjects_dir(fs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To create the `FreeSurferSource` node, do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import Node\n",
    "from nipype.interfaces.io import FreeSurferSource\n",
    "\n",
    "# Create FreeSurferSource node\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                name='fssource')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now run it for a specific subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170302-17:50:07,668 workflow INFO:\n",
      "\t Executing node fssource in dir: /tmp/tmpI0UTIX/fssource\n"
     ]
    }
   ],
   "source": [
    "fssource.inputs.subject_id = 'sub001'\n",
    "result = fssource.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Did it work? Let's try to access multiple FreeSurfer outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aparc_aseg: [u'/data/ds102/freesurfer/sub001/mri/aparc.a2009s+aseg.mgz', u'/data/ds102/freesurfer/sub001/mri/aparc+aseg.mgz']\n",
      "\n",
      "brainmask: /data/ds102/freesurfer/sub001/mri/brainmask.mgz\n",
      "\n",
      "inflated: [u'/data/ds102/freesurfer/sub001/surf/rh.inflated', u'/data/ds102/freesurfer/sub001/surf/lh.inflated']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'aparc_aseg: %s\\n' % result.outputs.aparc_aseg\n",
    "print 'brainmask: %s\\n' % result.outputs.brainmask\n",
    "print 'inflated: %s\\n' % result.outputs.inflated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems to be working as it should. But as you can see, the `inflated` output actually contains the file location for both hemispheres. With `FreeSurferSource` we can also restrict the file selection to a single hemisphere. To do this, we use the `hemi` input filed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170302-17:50:13,835 workflow INFO:\n",
      "\t Executing node fssource in dir: /tmp/tmpI0UTIX/fssource\n"
     ]
    }
   ],
   "source": [
    "fssource.inputs.hemi = 'lh'\n",
    "result = fssource.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look again at the `inflated` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/data/ds102/freesurfer/sub001/surf/lh.inflated'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.outputs.inflated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perfect!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
